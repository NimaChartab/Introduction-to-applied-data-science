{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes spam filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider that you are given a data set of text messages which are labeled with ham or spam. We will use a training sample with ~4000 text messages, but first let's consider a few examples to get familiar with the naive Bayes idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Class| Message|Bag of words|\n",
    "| -|:-:|:-:|\n",
    "| Spam| Send us your password| send, password|\n",
    "| Ham| I will send you the letter| send, letter|\n",
    "| Ham| I wrote a letter | write, letter|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compute P(Spam|Bag of words). Last session, we learned from Bayes' rule:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"center\">$P(\\text{Spam|Bag of words})= \\frac{P(\\text{Bag of words|Spam})P(\\text{Spam})}{P(\\text{Bag of words|Spam})P(\\text{Spam})+P(\\text{Bag of words|Ham})P(\\text{Ham})}$</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(word|spam) and P(word|ham) can be estimated from the training sample. To avoid zero probabilities, we consider the initial value of 1 for the number of occurence of a word. Note that the priors are P(ham)=$\\frac{2}{3}$ and P(spam)=$\\frac{1}{3}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Spam| Ham|word|Spam(i=1) |Ham(i=1)|\n",
    "| -|:-:|:-:|:-:|:-:|\n",
    "|$\\frac{1}{2}$ |$\\frac{1}{4}$ |send|$\\frac{1+1}{2+4}$ |$\\frac{1+1}{4+4}$ |\n",
    "|$\\frac{1}{2}$ |$\\frac{0}{4}$ |password|$\\frac{1+1}{2+4}$ |$\\frac{0+1}{4+4}$ |\n",
    "|$\\frac{0}{2}$| $\\frac{2}{4}$|letter|$\\frac{0+1}{2+4}$| $\\frac{2+1}{4+4}$|\n",
    "|$\\frac{0}{2}$ |$\\frac{1}{4}$ |write|$\\frac{0+1}{2+4}$ |$\\frac{1+1}{4+4}$ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, consider a new text message \"*write your password in the password box*\". We don't have the word \"*box*\" in our training sample, so the safe choice would be to remove this from the bag of words and make decision based on on the other two words, \"*write*\" and \"*password*\". \"*password*\" occured twice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">$P(\\text{spam|write,password,password})= \\frac{P(\\text{write|spam})P(\\text{password|spam})P(\\text{password|spam})P(\\text{spam})}{P(\\text{write|Spam})P(\\text{password|Spam})P(\\text{password|spam})P(\\text{Spam})+P(\\text{write|ham})P(\\text{password|ham})P(\\text{password|ham})P(\\text{ham})}$</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">$P(\\text{spam|write,password,password})= \\frac{\\frac{1}{6}\\times\\frac{2}{6}\\times\\frac{2}{6}\\times\\frac{1}{3}}{\\frac{1}{6}\\times\\frac{2}{6}\\times\\frac{2}{6}\\times\\frac{1}{3}+\\frac{2}{8}\\times\\frac{1}{8}\\times\\frac{1}{8}\\times\\frac{2}{3}}\\sim 70\\%$</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and $P(\\text{ham|write,password,password})=1-P(\\text{spam|write,password,password})=30\\%$, so we classify this email as a spam message. This was just a demonsteration of the naive Bayes method. Let's use a large data set to build a model and evaluate its performance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK (Natural Language Toolkit) is a set of libraries for Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/nima/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words are the most common words in a language which don't carry much information. We will filter them before NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we']\n"
     ]
    }
   ],
   "source": [
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "print(stopwords[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A word can have many variations with the same meaning. So, we will use stem package to normalize the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cook', 'cook', 'cook')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "Ps=PorterStemmer()\n",
    "Ps.stem('cook'),Ps.stem('cooking'),Ps.stem('cooked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to remove punctuations, they are not informative in our classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punctuations=string.punctuation\n",
    "print(punctuations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('spam.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change categorical data into numbers which can be processed in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text  Class_code\n",
       "0   ham  Go until jurong point, crazy.. Available only ...           0\n",
       "1   ham                      Ok lar... Joking wif u oni...           0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...           1\n",
       "3   ham  U dun say so early hor... U c already then say...           0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...           0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class_code']=pd.get_dummies(data.Class,drop_first=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataframe,test_size=0.3,rs=None):\n",
    "    \"\"\"A function which takes pandas dataframe and split it to train and test samples\"\"\"\n",
    "    dataframe_test=dataframe.sample(frac=test_size,random_state=rs)\n",
    "    dataframe_train=dataframe.loc[dataframe.index.difference(dataframe_test.index)]\n",
    "    \n",
    "    return (dataframe_train.reset_index(drop=True),dataframe_test.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train,data_test=train_test_split(data,test_size=0.3,rs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text  Class_code\n",
       "0   ham  Go until jurong point, crazy.. Available only ...           0\n",
       "1   ham                      Ok lar... Joking wif u oni...           0\n",
       "2   ham  U dun say so early hor... U c already then say...           0\n",
       "3  spam  FreeMsg Hey there darling it's been 3 week's n...           1\n",
       "4   ham  Even my brother is not like to speak with me. ...           0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>No problem. Talk to you later</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>No idea, I guess we'll work that out an hour a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Em, its olowoyey@ usc.edu have a great time in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm in a movie... Collect car oredi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry man, accidentally left my phone on silen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text  Class_code\n",
       "0   ham                      No problem. Talk to you later           0\n",
       "1   ham  No idea, I guess we'll work that out an hour a...           0\n",
       "2   ham  Em, its olowoyey@ usc.edu have a great time in...           0\n",
       "3   ham             I'm in a movie... Collect car oredi...           0\n",
       "4   ham  Sorry man, accidentally left my phone on silen...           0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up one of the text messages as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your gonna have to pick up a $1 burger for yourself on your way home. I can't even move. Pain is killing me.\n"
     ]
    }
   ],
   "source": [
    "message=data_train.Text[46]\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your gonna have to pick up a $1 burger for yourself on your way home. i can't even move. pain is killing me.\n"
     ]
    }
   ],
   "source": [
    "#convert to lower case\n",
    "message=message.lower()\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your gonna have to pick up a 1 burger for yourself on your way home i cant even move pain is killing me\n"
     ]
    }
   ],
   "source": [
    "message=''.join([x for x in message if x not in punctuations])\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gonna', 'pick', '1', 'burger', 'way', 'home', 'cant', 'even', 'move', 'pain', 'killing']\n"
     ]
    }
   ],
   "source": [
    "message=[x for x in message.split() if x not in stopwords]\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gonna', 'pick', '1', 'burger', 'way', 'home', 'cant', 'even', 'move', 'pain', 'kill']\n"
     ]
    }
   ],
   "source": [
    "message=[Ps.stem(x) for x in message]\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'gonna': 1, 'pick': 1, '1': 1, 'burger': 1, 'way': 1, 'home': 1, 'cant': 1, 'even': 1, 'move': 1, 'pain': 1, 'kill': 1})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now put them together in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message(message):\n",
    "    \"\"\"a function to clean up message and return a dict with bag of their occurence rate\"\"\"\n",
    "    message=message.lower()\n",
    "    message=''.join([x for x in message if x not in punctuations])\n",
    "    message=[x for x in message.split() if x not in stopwords]\n",
    "    message=[Ps.stem(x) for x in message]\n",
    "    return(Counter(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the plural of the noun research?\n",
      "Counter({'plural': 1, 'noun': 1, 'research': 1})\n"
     ]
    }
   ],
   "source": [
    "print(data_train.Text[80])\n",
    "print(clean_message(data_train.Text[80]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to all the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class_code</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'go': 1, 'jurong': 1, 'point': 1, 'crazi': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'ok': 1, 'lar': 1, 'joke': 1, 'wif': 1, 'u': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'u': 2, 'dun': 1, 'say': 2, 'earli': 1, 'hor'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'freemsg': 1, 'hey': 1, 'darl': 1, '3': 1, 'w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'even': 1, 'brother': 1, 'like': 2, 'speak': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text  Class_code  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...           0   \n",
       "1   ham                      Ok lar... Joking wif u oni...           0   \n",
       "2   ham  U dun say so early hor... U c already then say...           0   \n",
       "3  spam  FreeMsg Hey there darling it's been 3 week's n...           1   \n",
       "4   ham  Even my brother is not like to speak with me. ...           0   \n",
       "\n",
       "                                        bag_of_words  \n",
       "0  {'go': 1, 'jurong': 1, 'point': 1, 'crazi': 1,...  \n",
       "1  {'ok': 1, 'lar': 1, 'joke': 1, 'wif': 1, 'u': ...  \n",
       "2  {'u': 2, 'dun': 1, 'say': 2, 'earli': 1, 'hor'...  \n",
       "3  {'freemsg': 1, 'hey': 1, 'darl': 1, '3': 1, 'w...  \n",
       "4  {'even': 1, 'brother': 1, 'like': 2, 'speak': ...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['bag_of_words']=data_train['Text'].apply(clean_message)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "bows=data_train.bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "bows_ham=data_train[data_train.Class_code==0].bag_of_words\n",
    "bows_spam=data_train[data_train.Class_code==1].bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=list(set().union(*bows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_occurence_ham={key:1 for key in words}\n",
    "for word in words:\n",
    "    for bow in bows_ham:\n",
    "        if word in bow.keys():\n",
    "            number_of_occurence_ham[word]+=bow[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_occurence_ham['soon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_occurence_spam={key:1 for key in words}\n",
    "for word in words:\n",
    "    for bow in bows_spam:\n",
    "        if word in bow.keys():\n",
    "            number_of_occurence_spam[word]+=bow[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_occurence_spam['free']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of a word given that the text is ham/spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_word_h={}\n",
    "P_word_s={}\n",
    "for key in number_of_occurence_ham:\n",
    "    P_word_h[key]=number_of_occurence_ham[key]/sum(number_of_occurence_ham.values())\n",
    "for key in number_of_occurence_spam:\n",
    "    P_word_s[key]=number_of_occurence_spam[key]/sum(number_of_occurence_spam.values())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_h=bows_ham.size/bows.size\n",
    "P_s=bows_spam.size/bows.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1310116086235489\n",
      "0.8689883913764511\n"
     ]
    }
   ],
   "source": [
    "print(P_s)\n",
    "print(P_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the main classifier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(document):\n",
    "    document_bag_of_words=clean_message(document)\n",
    "    P_document_h=1\n",
    "    P_document_s=1\n",
    "    for key in document_bag_of_words:\n",
    "        if key in words:\n",
    "            P_document_h=P_document_h*P_word_h[key]\n",
    "            P_document_s=P_document_s*P_word_s[key]\n",
    "    P_document_h=P_document_h*P_h\n",
    "    P_document_s=P_document_s*P_s\n",
    "    \n",
    "    Pr_doc_h_normalized=P_document_h/(P_document_h+P_document_s)\n",
    "    \n",
    "    if Pr_doc_h_normalized>0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "classifier=np.vectorize(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('congratulations! you won $500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Let's apply this model to the test sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=classifier(data_test.Text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=data_test.Class_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP,TN,FP,FN=0,0,0,0\n",
    "for i in range(len(T)):\n",
    "    if T[i]==1:\n",
    "        if prediction[i]==1:\n",
    "            TP+=1\n",
    "        if prediction[i]==0:\n",
    "            FN+=1\n",
    "    if T[i]==0:\n",
    "        if prediction[i]==1:\n",
    "            FP+=1\n",
    "        if prediction[i]==0:\n",
    "            TN+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 158    9]\n",
      " [  21 1363]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([[TP,FP],[FN,TN]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision= 0.9461077844311377\n"
     ]
    }
   ],
   "source": [
    "precision=TP/(TP+FP)\n",
    "print(\"precision=\",precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall= 0.88268156424581\n"
     ]
    }
   ],
   "source": [
    "recall=TP/(TP+FN)\n",
    "print(\"recall=\",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score= 0.9132947976878613\n"
     ]
    }
   ],
   "source": [
    "F1_score=2*precision*recall/(precision+recall)\n",
    "print(\"F1_score=\",F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.9806576402321083\n"
     ]
    }
   ],
   "source": [
    "accuracy=(TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"accuracy=\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PHYS247",
   "language": "python",
   "name": "phys247"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
